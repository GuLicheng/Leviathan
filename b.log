INFO:2022-04-11 13:24:36:=====================================================================================
INFO:2022-04-11 13:24:36:COCO best method
INFO:2022-04-11 13:24:36:=====================================================================================
INFO:2022-04-11 13:24:36:data_root = voc
INFO:2022-04-11 13:24:36:image_directory = voc/JPEGImages
INFO:2022-04-11 13:24:36:semantic_directory = voc/SegmentationClassAug
INFO:2022-04-11 13:24:36:train_aug_txt = data/voc/train_aug.txt
INFO:2022-04-11 13:24:36:train_txt = data/voc/train.txt
INFO:2022-04-11 13:24:36:val_txt = data/voc/val.txt
INFO:2022-04-11 13:24:36:image_level_npy = data/voc/cls_labels_onehot.npy
INFO:2022-04-11 13:24:36:work_dir = result/voc3
INFO:2022-04-11 13:24:36:local_rank = 0
INFO:2022-04-11 13:24:36:arch = vit_small
INFO:2022-04-11 13:24:36:num_classes = 20
INFO:2022-04-11 13:24:36:image_size = 384
INFO:2022-04-11 13:24:36:cam_loss_weight = 0.1
INFO:2022-04-11 13:24:36:crf_loss_weight = 0.1
INFO:2022-04-11 13:24:36:seg_loss_weight = 1.0
INFO:2022-04-11 13:24:36:cls_head_lr_weight = 10.0
INFO:2022-04-11 13:24:36:seg_head_lr_weight = 15.0
INFO:2022-04-11 13:24:36:crop_size = 384
INFO:2022-04-11 13:24:36:lr = 1.25e-05
INFO:2022-04-11 13:24:36:eps = 1e-08
INFO:2022-04-11 13:24:36:epochs = 30
INFO:2022-04-11 13:24:36:weight_decay = 0.0
INFO:2022-04-11 13:24:36:betas = [0.9, 0.999]
INFO:2022-04-11 13:24:36:momentum = 0.9
INFO:2022-04-11 13:24:36:warmup_iter = 2000
INFO:2022-04-11 13:24:36:warmup_ratio = 1e-06
INFO:2022-04-11 13:24:36:power = 0.9
INFO:2022-04-11 13:24:36:sample_per_gpu = 16
INFO:2022-04-11 13:24:36:num_workers = 8
INFO:2022-04-11 13:24:36:seed = 17
INFO:2022-04-11 13:24:36:pretrained = /home/ubuntu/S_16-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz
INFO:2022-04-11 13:24:36:session = COCO best method
INFO:2022-04-11 13:24:36:=====================================================================================
INFO:2022-04-11 13:24:36:============================DATASET=================================
INFO:2022-04-11 13:24:36:Train set:
INFO:2022-04-11 13:24:36:Dataset: PascalVoc with 10582 samples
Pipeline:
Compose(
    ReadImage { args : ['image'] }
    RandomScaleCrop { args : ['image'] size : (384, 384) scale : (0.5, 2.0) ratio : (0.75, 1.3333333333333333) }
    RandomHorizontalFlip { args : ['image'] ratio : 0.5 }
    ColorJitterImage { args : ['image'] brightness : 0.3 contrast : 0.3 saturation : 0.3 hue : 0.1 }
    ToTensor { args : ['image'] }
    NormalizeImage { args : ['image'] mean : [123.675, 116.28, 103.53] std : [58.395, 57.12, 57.375] }
)
INFO:2022-04-11 13:24:36:Val set:
INFO:2022-04-11 13:24:36:Dataset: PascalVoc with 1449 samples
Pipeline:
Compose(
    ReadImage { args : ['image'] }
    ReadAnnotation { args : ['semantic'] }
    ToTensor { args : ['image', 'semantic'] }
    NormalizeImage { args : ['image'] mean : [123.675, 116.28, 103.53] std : [58.395, 57.12, 57.375] }
)
INFO:2022-04-11 13:24:36:============================DATASET=================================
INFO:2022-04-11 13:24:37:VisualTransformerClassifierV2(
  (backbone): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
    (head): Identity()
    (pre_logits): Identity()
  )
  (blk): TransformerBlock(
    (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=384, out_features=1152, bias=True)
      (attn_drop): Dropout(p=0, inplace=False)
      (proj): Linear(in_features=384, out_features=384, bias=True)
      (proj_drop): Dropout(p=0, inplace=False)
    )
    (drop_path): Identity()
    (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=384, out_features=1536, bias=True)
      (act): GELU(approximate=none)
      (fc2): Linear(in_features=1536, out_features=384, bias=True)
      (drop): Dropout(p=0, inplace=False)
    )
  )
  (norm): Identity()
  (head): Conv2d(384, 20, kernel_size=(1, 1), stride=(1, 1))
  (seghead): MaskTransformer(
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (mlp): FeedForward(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (mlp): FeedForward(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.100)
      )
    )
    (proj_dec): Linear(in_features=384, out_features=384, bias=True)
    (decoder_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (mask_norm): LayerNorm((21,), eps=1e-05, elementwise_affine=True)
  )
)
INFO:2022-04-11 13:24:40:Training: 0
INFO:2022-04-11 13:26:42:lr = [0.0009258879096791951, 0.00925887909679195, 0.013888318645187926]
INFO:2022-04-11 13:26:42:Train Loss: 1.5540, cls: 0.1502, ce: 0.9726,crf: 0.3015, cam: 0.1297.
INFO:2022-04-11 13:26:42:Training: Epoch: 0/30
INFO:2022-04-11 13:26:42:Loss: 1.5540
INFO:2022-04-11 13:26:42:Validation: 0
INFO:2022-04-11 13:26:50:Testing Epoch: 0/30, mAP=0.9357, mIoU=0.6080, acc=0.5978
INFO:2022-04-11 13:26:50:Training: 1
INFO:2022-04-11 13:28:47:lr = [0.000850651767654213, 0.00850651767654213, 0.012759776514813194]
INFO:2022-04-11 13:28:47:Train Loss: 1.0704, cls: 0.0775, ce: 0.7063,crf: 0.2106, cam: 0.0760.
INFO:2022-04-11 13:28:47:Training: Epoch: 1/30
INFO:2022-04-11 13:28:47:Loss: 1.0704
INFO:2022-04-11 13:28:47:Validation: 1
INFO:2022-04-11 13:28:55:Testing Epoch: 1/30, mAP=0.9520, mIoU=0.6296, acc=0.7025
INFO:2022-04-11 13:28:55:Training: 2
INFO:2022-04-11 13:30:53:lr = [0.0007746677540007383, 0.007746677540007383, 0.011620016310011074]
INFO:2022-04-11 13:30:53:Train Loss: 0.9854, cls: 0.0681, ce: 0.6619,crf: 0.1801, cam: 0.0752.
INFO:2022-04-11 13:30:53:Training: Epoch: 2/30
INFO:2022-04-11 13:30:53:Loss: 0.9854
INFO:2022-04-11 13:30:53:Validation: 2
INFO:2022-04-11 13:31:01:Testing Epoch: 2/30, mAP=0.9600, mIoU=0.6568, acc=0.7025
INFO:2022-04-11 13:31:01:Training: 3
INFO:2022-04-11 13:32:58:lr = [0.0006978448920310331, 0.006978448920310332, 0.010467673380465498]
INFO:2022-04-11 13:32:58:Train Loss: 0.9341, cls: 0.0628, ce: 0.6284,crf: 0.1745, cam: 0.0684.
INFO:2022-04-11 13:32:58:Training: Epoch: 3/30
INFO:2022-04-11 13:32:58:Loss: 0.9341
INFO:2022-04-11 13:32:58:Validation: 3
INFO:2022-04-11 13:33:06:Testing Epoch: 3/30, mAP=0.9634, mIoU=0.6608, acc=0.7135
INFO:2022-04-11 13:33:06:Training: 4
INFO:2022-04-11 13:35:02:lr = [0.0006200683916118909, 0.006200683916118909, 0.009301025874178363]
INFO:2022-04-11 13:35:02:Train Loss: 0.8891, cls: 0.0571, ce: 0.5970,crf: 0.1687, cam: 0.0664.
INFO:2022-04-11 13:35:02:Training: Epoch: 4/30
INFO:2022-04-11 13:35:02:Loss: 0.8891
INFO:2022-04-11 13:35:02:Validation: 4
INFO:2022-04-11 13:35:10:Testing Epoch: 4/30, mAP=0.9697, mIoU=0.6526, acc=0.7328
INFO:2022-04-11 13:35:10:Training: 5
INFO:2022-04-11 13:37:22:lr = [0.0005411891037058208, 0.0054118910370582075, 0.008117836555587312]
INFO:2022-04-11 13:37:22:Train Loss: 0.8649, cls: 0.0573, ce: 0.5839,crf: 0.1564, cam: 0.0672.
INFO:2022-04-11 13:37:22:Training: Epoch: 5/30
INFO:2022-04-11 13:37:22:Loss: 0.8649
INFO:2022-04-11 13:37:22:Validation: 5
INFO:2022-04-11 13:37:33:Testing Epoch: 5/30, mAP=0.9704, mIoU=0.6532, acc=0.7521
INFO:2022-04-11 13:37:33:Training: 6
INFO:2022-04-11 13:40:12:lr = [0.00046100573766162786, 0.004610057376616279, 0.006915086064924417]
INFO:2022-04-11 13:40:12:Train Loss: 0.8650, cls: 0.0568, ce: 0.5874,crf: 0.1556, cam: 0.0652.
INFO:2022-04-11 13:40:12:Training: Epoch: 6/30
INFO:2022-04-11 13:40:12:Loss: 0.8650
INFO:2022-04-11 13:40:12:Validation: 6
INFO:2022-04-11 13:40:24:Testing Epoch: 6/30, mAP=0.9666, mIoU=0.6520, acc=0.7383
INFO:2022-04-11 13:40:24:Training: 7
INFO:2022-04-11 13:42:36:lr = [0.0003792323738936543, 0.003792323738936543, 0.0056884856084048144]
INFO:2022-04-11 13:42:36:Train Loss: 0.8536, cls: 0.0564, ce: 0.5727,crf: 0.1629, cam: 0.0616.
INFO:2022-04-11 13:42:36:Training: Epoch: 7/30
INFO:2022-04-11 13:42:36:Loss: 0.8536
INFO:2022-04-11 13:42:36:Validation: 7
INFO:2022-04-11 13:42:45:Testing Epoch: 7/30, mAP=0.9677, mIoU=0.6410, acc=0.7521
INFO:2022-04-11 13:42:45:Training: 8
INFO:2022-04-11 13:44:50:lr = [0.0002954321366096037, 0.0029543213660960365, 0.004431482049144056]
INFO:2022-04-11 13:44:50:Train Loss: 0.8517, cls: 0.0563, ce: 0.5717,crf: 0.1584, cam: 0.0653.
INFO:2022-04-11 13:44:50:Training: Epoch: 8/30
INFO:2022-04-11 13:44:50:Loss: 0.8517
INFO:2022-04-11 13:44:50:Validation: 8
INFO:2022-04-11 13:44:59:Testing Epoch: 8/30, mAP=0.9662, mIoU=0.6377, acc=0.7631
INFO:2022-04-11 13:44:59:Training: 9
INFO:2022-04-11 13:46:56:lr = [0.00020885717946126755, 0.002088571794612675, 0.003132857691919013]
INFO:2022-04-11 13:46:56:Train Loss: 0.8462, cls: 0.0543, ce: 0.5699,crf: 0.1589, cam: 0.0630.
INFO:2022-04-11 13:46:56:Training: Epoch: 9/30
INFO:2022-04-11 13:46:56:Loss: 0.8462
INFO:2022-04-11 13:46:56:Validation: 9
INFO:2022-04-11 13:47:04:Testing Epoch: 9/30, mAP=0.9672, mIoU=0.6505, acc=0.7576
INFO:2022-04-11 13:47:04:Training: 10
INFO:2022-04-11 13:49:01:lr = [0.00011793281191331187, 0.0011793281191331186, 0.0017689921786996781]
INFO:2022-04-11 13:49:01:Train Loss: 0.8022, cls: 0.0530, ce: 0.5419,crf: 0.1424, cam: 0.0649.
INFO:2022-04-11 13:49:01:Training: Epoch: 10/30
INFO:2022-04-11 13:49:01:Loss: 0.8022
INFO:2022-04-11 13:49:01:Validation: 10
INFO:2022-04-11 13:49:09:Testing Epoch: 10/30, mAP=0.9696, mIoU=0.6524, acc=0.7548
INFO:2022-04-11 13:49:10:Training: 11
INFO:2022-04-11 13:51:06:lr = [1.6560382712451324e-05, 0.00016560382712451323, 0.00024840574068676983]
INFO:2022-04-11 13:51:06:Train Loss: 0.7685, cls: 0.0529, ce: 0.5164,crf: 0.1369, cam: 0.0623.
INFO:2022-04-11 13:51:06:Training: Epoch: 11/30
INFO:2022-04-11 13:51:06:Loss: 0.7685
INFO:2022-04-11 13:51:06:Validation: 11
INFO:2022-04-11 13:51:14:Testing Epoch: 11/30, mAP=0.9701, mIoU=0.6628, acc=0.7521
INFO:2022-04-11 13:51:14:Training: 12
INFO:2022-04-11 13:53:11:lr = [9.559586023932047e-05, 0.0009559586023932047, 0.001433937903589807]
INFO:2022-04-11 13:53:11:Train Loss: 0.7783, cls: 0.0522, ce: 0.5252,crf: 0.1368, cam: 0.0641.
INFO:2022-04-11 13:53:11:Training: Epoch: 12/30
INFO:2022-04-11 13:53:11:Loss: 0.7783
INFO:2022-04-11 13:53:11:Validation: 12
INFO:2022-04-11 13:53:19:Testing Epoch: 12/30, mAP=0.9707, mIoU=0.6660, acc=0.7521
INFO:2022-04-11 13:53:19:Training: 13
INFO:2022-04-11 13:55:18:lr = [9.05215010050999e-05, 0.0009052150100509989, 0.0013578225150764984]
INFO:2022-04-11 13:55:18:Train Loss: 0.7672, cls: 0.0515, ce: 0.5160,crf: 0.1355, cam: 0.0642.
INFO:2022-04-11 13:55:18:Training: Epoch: 13/30
INFO:2022-04-11 13:55:18:Loss: 0.7672
INFO:2022-04-11 13:55:18:Validation: 13
INFO:2022-04-11 13:55:26:Testing Epoch: 13/30, mAP=0.9702, mIoU=0.6586, acc=0.7658
INFO:2022-04-11 13:55:26:Training: 14
INFO:2022-04-11 13:57:24:lr = [8.54153179675496e-05, 0.0008541531796754959, 0.0012812297695132438]
INFO:2022-04-11 13:57:24:Train Loss: 0.7428, cls: 0.0502, ce: 0.4977,crf: 0.1334, cam: 0.0615.
INFO:2022-04-11 13:57:24:Training: Epoch: 14/30
INFO:2022-04-11 13:57:24:Loss: 0.7428
INFO:2022-04-11 13:57:24:Validation: 14
INFO:2022-04-11 13:57:32:Testing Epoch: 14/30, mAP=0.9718, mIoU=0.6668, acc=0.7658
INFO:2022-04-11 13:57:32:Training: 15
INFO:2022-04-11 13:59:29:lr = [8.027496715621114e-05, 0.0008027496715621113, 0.001204124507343167]
INFO:2022-04-11 13:59:29:Train Loss: 0.7544, cls: 0.0522, ce: 0.5058,crf: 0.1338, cam: 0.0626.
INFO:2022-04-11 13:59:29:Training: Epoch: 15/30
INFO:2022-04-11 13:59:29:Loss: 0.7544
INFO:2022-04-11 13:59:29:Validation: 15
INFO:2022-04-11 13:59:37:Testing Epoch: 15/30, mAP=0.9707, mIoU=0.6572, acc=0.7603
INFO:2022-04-11 13:59:37:Training: 16
INFO:2022-04-11 14:01:34:lr = [7.509775106572544e-05, 0.0007509775106572544, 0.0011264662659858816]
INFO:2022-04-11 14:01:34:Train Loss: 0.7209, cls: 0.0504, ce: 0.4790,crf: 0.1309, cam: 0.0605.
INFO:2022-04-11 14:01:34:Training: Epoch: 16/30
INFO:2022-04-11 14:01:34:Loss: 0.7209
INFO:2022-04-11 14:01:34:Validation: 16
INFO:2022-04-11 14:01:42:Testing Epoch: 16/30, mAP=0.9699, mIoU=0.6545, acc=0.7548
INFO:2022-04-11 14:01:42:Training: 17
INFO:2022-04-11 14:03:39:lr = [6.988053376996817e-05, 0.0006988053376996817, 0.0010482080065495226]
INFO:2022-04-11 14:03:39:Train Loss: 0.7405, cls: 0.0507, ce: 0.4904,crf: 0.1367, cam: 0.0627.
INFO:2022-04-11 14:03:39:Training: Epoch: 17/30
INFO:2022-04-11 14:03:39:Loss: 0.7405
INFO:2022-04-11 14:03:39:Validation: 17
INFO:2022-04-11 14:03:47:Testing Epoch: 17/30, mAP=0.9702, mIoU=0.6556, acc=0.7631
INFO:2022-04-11 14:03:47:Training: 18
INFO:2022-04-11 14:05:45:lr = [6.461962678415633e-05, 0.0006461962678415633, 0.0009692944017623448]
INFO:2022-04-11 14:05:45:Train Loss: 0.7249, cls: 0.0502, ce: 0.4821,crf: 0.1308, cam: 0.0618.
INFO:2022-04-11 14:05:45:Training: Epoch: 18/30
INFO:2022-04-11 14:05:45:Loss: 0.7249
INFO:2022-04-11 14:05:45:Validation: 18
INFO:2022-04-11 14:05:53:Testing Epoch: 18/30, mAP=0.9699, mIoU=0.6562, acc=0.7631
INFO:2022-04-11 14:05:53:Training: 19
INFO:2022-04-11 14:07:50:lr = [5.931063196713951e-05, 0.0005931063196713951, 0.0008896594795070926]
INFO:2022-04-11 14:07:50:Train Loss: 0.7026, cls: 0.0475, ce: 0.4647,crf: 0.1314, cam: 0.0591.
INFO:2022-04-11 14:07:50:Training: Epoch: 19/30
INFO:2022-04-11 14:07:50:Loss: 0.7026
INFO:2022-04-11 14:07:50:Validation: 19
INFO:2022-04-11 14:07:58:Testing Epoch: 19/30, mAP=0.9710, mIoU=0.6600, acc=0.7686
INFO:2022-04-11 14:07:58:Training: 20
INFO:2022-04-11 14:09:56:lr = [5.394821928196066e-05, 0.0005394821928196065, 0.0008092232892294098]
INFO:2022-04-11 14:09:56:Train Loss: 0.7243, cls: 0.0494, ce: 0.4833,crf: 0.1286, cam: 0.0630.
INFO:2022-04-11 14:09:56:Training: Epoch: 20/30
INFO:2022-04-11 14:09:56:Loss: 0.7243
INFO:2022-04-11 14:09:56:Validation: 20
INFO:2022-04-11 14:10:04:Testing Epoch: 20/30, mAP=0.9708, mIoU=0.6596, acc=0.7631
INFO:2022-04-11 14:10:04:Training: 21
INFO:2022-04-11 14:12:01:lr = [4.8525801960019504e-05, 0.0004852580196001951, 0.0007278870294002926]
INFO:2022-04-11 14:12:01:Train Loss: 0.7057, cls: 0.0483, ce: 0.4689,crf: 0.1270, cam: 0.0615.
INFO:2022-04-11 14:12:01:Training: Epoch: 21/30
INFO:2022-04-11 14:12:01:Loss: 0.7057
INFO:2022-04-11 14:12:01:Validation: 21
INFO:2022-04-11 14:12:10:Testing Epoch: 21/30, mAP=0.9705, mIoU=0.6589, acc=0.7603
INFO:2022-04-11 14:12:10:Training: 22
INFO:2022-04-11 14:14:07:lr = [4.3035042509790234e-05, 0.0004303504250979023, 0.0006455256376468535]
INFO:2022-04-11 14:14:07:Train Loss: 0.7192, cls: 0.0495, ce: 0.4776,crf: 0.1311, cam: 0.0609.
INFO:2022-04-11 14:14:07:Training: Epoch: 22/30
INFO:2022-04-11 14:14:07:Loss: 0.7192
INFO:2022-04-11 14:14:07:Validation: 22
INFO:2022-04-11 14:14:15:Testing Epoch: 22/30, mAP=0.9700, mIoU=0.6493, acc=0.7576
INFO:2022-04-11 14:14:15:Training: 23
INFO:2022-04-11 14:16:12:lr = [3.746506364066295e-05, 0.0003746506364066295, 0.0005619759546099442]
INFO:2022-04-11 14:16:12:Train Loss: 0.7167, cls: 0.0493, ce: 0.4767,crf: 0.1296, cam: 0.0611.
INFO:2022-04-11 14:16:12:Training: Epoch: 23/30
INFO:2022-04-11 14:16:12:Loss: 0.7167
INFO:2022-04-11 14:16:12:Validation: 23
INFO:2022-04-11 14:16:20:Testing Epoch: 23/30, mAP=0.9706, mIoU=0.6590, acc=0.7658
INFO:2022-04-11 14:16:20:Training: 24
INFO:2022-04-11 14:18:17:lr = [3.180110627669995e-05, 0.0003180110627669995, 0.00047701659415049923]
INFO:2022-04-11 14:18:17:Train Loss: 0.7331, cls: 0.0492, ce: 0.4920,crf: 0.1285, cam: 0.0633.
INFO:2022-04-11 14:18:17:Training: Epoch: 24/30
INFO:2022-04-11 14:18:17:Loss: 0.7331
INFO:2022-04-11 14:18:17:Validation: 24
INFO:2022-04-11 14:18:25:Testing Epoch: 24/30, mAP=0.9704, mIoU=0.6624, acc=0.7686
INFO:2022-04-11 14:18:25:Training: 25
INFO:2022-04-11 14:20:22:lr = [2.6022049529615333e-05, 0.00026022049529615335, 0.00039033074294423]
INFO:2022-04-11 14:20:22:Train Loss: 0.7217, cls: 0.0489, ce: 0.4806,crf: 0.1312, cam: 0.0609.
INFO:2022-04-11 14:20:22:Training: Epoch: 25/30
INFO:2022-04-11 14:20:22:Loss: 0.7217
INFO:2022-04-11 14:20:22:Validation: 25
INFO:2022-04-11 14:20:30:Testing Epoch: 25/30, mAP=0.9707, mIoU=0.6554, acc=0.7686
INFO:2022-04-11 14:20:31:Training: 26
INFO:2022-04-11 14:22:28:lr = [2.0095262999833883e-05, 0.00020095262999833883, 0.00030142894499750827]
INFO:2022-04-11 14:22:28:Train Loss: 0.7181, cls: 0.0494, ce: 0.4766,crf: 0.1310, cam: 0.0612.
INFO:2022-04-11 14:22:28:Training: Epoch: 26/30
INFO:2022-04-11 14:22:28:Loss: 0.7181
INFO:2022-04-11 14:22:28:Validation: 26
INFO:2022-04-11 14:22:36:Testing Epoch: 26/30, mAP=0.9699, mIoU=0.6574, acc=0.7631
INFO:2022-04-11 14:22:36:Training: 27
INFO:2022-04-11 14:24:32:lr = [1.3963856593028266e-05, 0.00013963856593028265, 0.00020945784889542398]
INFO:2022-04-11 14:24:32:Train Loss: 0.7195, cls: 0.0497, ce: 0.4797,crf: 0.1281, cam: 0.0620.
INFO:2022-04-11 14:24:32:Training: Epoch: 27/30
INFO:2022-04-11 14:24:32:Loss: 0.7195
INFO:2022-04-11 14:24:32:Validation: 27
INFO:2022-04-11 14:24:40:Testing Epoch: 27/30, mAP=0.9700, mIoU=0.6588, acc=0.7686
INFO:2022-04-11 14:24:40:Training: 28
INFO:2022-04-11 14:26:36:lr = [7.50338904472446e-06, 7.50338904472446e-05, 0.0001125508356708669]
INFO:2022-04-11 14:26:36:Train Loss: 0.6897, cls: 0.0485, ce: 0.4534,crf: 0.1287, cam: 0.0592.
INFO:2022-04-11 14:26:36:Training: Epoch: 28/30
INFO:2022-04-11 14:26:36:Loss: 0.6897
INFO:2022-04-11 14:26:36:Validation: 28
INFO:2022-04-11 14:26:44:Testing Epoch: 28/30, mAP=0.9698, mIoU=0.6579, acc=0.7658
INFO:2022-04-11 14:26:44:Training: 29
INFO:2022-04-11 14:28:42:lr = [7.536334834191402e-08, 7.536334834191402e-07, 1.1304502251287102e-06]
INFO:2022-04-11 14:28:42:Train Loss: 0.7000, cls: 0.0494, ce: 0.4607,crf: 0.1276, cam: 0.0623.
INFO:2022-04-11 14:28:42:Training: Epoch: 29/30
INFO:2022-04-11 14:28:42:Loss: 0.7000
INFO:2022-04-11 14:28:42:Validation: 29
INFO:2022-04-11 14:28:50:Testing Epoch: 29/30, mAP=0.9698, mIoU=0.6583, acc=0.7658
