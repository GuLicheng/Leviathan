INFO:2022-04-11 10:28:41:=====================================================================================
INFO:2022-04-11 10:28:41:COCO best method
INFO:2022-04-11 10:28:41:=====================================================================================
INFO:2022-04-11 10:28:41:data_root = voc
INFO:2022-04-11 10:28:41:image_directory = voc/JPEGImages
INFO:2022-04-11 10:28:41:semantic_directory = voc/SegmentationClassAug
INFO:2022-04-11 10:28:41:train_aug_txt = data/voc/train_aug.txt
INFO:2022-04-11 10:28:41:train_txt = data/voc/train.txt
INFO:2022-04-11 10:28:41:val_txt = data/voc/val.txt
INFO:2022-04-11 10:28:41:image_level_npy = data/voc/cls_labels_onehot.npy
INFO:2022-04-11 10:28:41:work_dir = result/voc2
INFO:2022-04-11 10:28:41:local_rank = 0
INFO:2022-04-11 10:28:41:arch = vit_small
INFO:2022-04-11 10:28:41:num_classes = 20
INFO:2022-04-11 10:28:41:image_size = 384
INFO:2022-04-11 10:28:41:cam_loss_weight = 0.1
INFO:2022-04-11 10:28:41:crf_loss_weight = 0.1
INFO:2022-04-11 10:28:41:seg_loss_weight = 1.0
INFO:2022-04-11 10:28:41:cls_head_lr_weight = 10.0
INFO:2022-04-11 10:28:41:seg_head_lr_weight = 15.0
INFO:2022-04-11 10:28:41:crop_size = 384
INFO:2022-04-11 10:28:41:lr = 1.25e-05
INFO:2022-04-11 10:28:41:eps = 1e-08
INFO:2022-04-11 10:28:41:epochs = 30
INFO:2022-04-11 10:28:41:weight_decay = 0.0
INFO:2022-04-11 10:28:41:betas = [0.9, 0.999]
INFO:2022-04-11 10:28:41:momentum = 0.9
INFO:2022-04-11 10:28:41:warmup_iter = 2000
INFO:2022-04-11 10:28:41:warmup_ratio = 1e-06
INFO:2022-04-11 10:28:41:power = 0.9
INFO:2022-04-11 10:28:41:sample_per_gpu = 16
INFO:2022-04-11 10:28:41:num_workers = 8
INFO:2022-04-11 10:28:41:seed = 17
INFO:2022-04-11 10:28:41:pretrained = /home/ubuntu/S_16-i21k-300ep-lr_0.001-aug_light1-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz
INFO:2022-04-11 10:28:41:session = COCO best method
INFO:2022-04-11 10:28:41:=====================================================================================
INFO:2022-04-11 10:28:41:============================DATASET=================================
INFO:2022-04-11 10:28:41:Train set:
INFO:2022-04-11 10:28:41:Dataset: PascalVoc with 10582 samples
Pipeline:
Compose(
    ReadImage { args : ['image'] }
    RandomScaleCrop { args : ['image'] size : (384, 384) scale : (0.5, 2.0) ratio : (0.75, 1.3333333333333333) }
    RandomHorizontalFlip { args : ['image'] ratio : 0.5 }
    ColorJitterImage { args : ['image'] brightness : 0.3 contrast : 0.3 saturation : 0.3 hue : 0.1 }
    ToTensor { args : ['image'] }
    NormalizeImage { args : ['image'] mean : [123.675, 116.28, 103.53] std : [58.395, 57.12, 57.375] }
)
INFO:2022-04-11 10:28:41:Val set:
INFO:2022-04-11 10:28:41:Dataset: PascalVoc with 1449 samples
Pipeline:
Compose(
    ReadImage { args : ['image'] }
    ReadAnnotation { args : ['semantic'] }
    ToTensor { args : ['image', 'semantic'] }
    NormalizeImage { args : ['image'] mean : [123.675, 116.28, 103.53] std : [58.395, 57.12, 57.375] }
)
INFO:2022-04-11 10:28:41:============================DATASET=================================
INFO:2022-04-11 10:28:42:VisualTransformerClassifierV2(
  (backbone): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
    (head): Identity()
    (pre_logits): Identity()
  )
  (blk): TransformerBlock(
    (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=384, out_features=1152, bias=True)
      (attn_drop): Dropout(p=0, inplace=False)
      (proj): Linear(in_features=384, out_features=384, bias=True)
      (proj_drop): Dropout(p=0, inplace=False)
    )
    (drop_path): Identity()
    (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=384, out_features=1536, bias=True)
      (act): GELU(approximate=none)
      (fc2): Linear(in_features=1536, out_features=384, bias=True)
      (drop): Dropout(p=0, inplace=False)
    )
  )
  (norm): Identity()
  (head): Conv2d(384, 20, kernel_size=(1, 1), stride=(1, 1))
  (seghead): MaskTransformer(
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (mlp): FeedForward(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (mlp): FeedForward(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.100)
      )
    )
    (proj_dec): Linear(in_features=384, out_features=384, bias=True)
    (decoder_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (mask_norm): LayerNorm((21,), eps=1e-05, elementwise_affine=True)
  )
)
INFO:2022-04-11 10:28:45:Training: 0
INFO:2022-04-11 10:30:46:lr = [0.0009258879096791951, 0.00925887909679195, 0.013888318645187926]
INFO:2022-04-11 10:30:46:Train Loss: 1.9974, cls: 0.1843, ce: 1.2685,crf: 0.4176, cam: 0.1271.
INFO:2022-04-11 10:30:46:Training: Epoch: 0/30
INFO:2022-04-11 10:30:46:Loss: 1.9974
INFO:2022-04-11 10:30:46:Validation: 0
INFO:2022-04-11 10:30:54:Testing Epoch: 0/30, mAP=0.9460, mIoU=0.5230, acc=0.6474
INFO:2022-04-11 10:30:54:Training: 1
INFO:2022-04-11 10:32:51:lr = [0.000850651767654213, 0.00850651767654213, 0.012759776514813194]
INFO:2022-04-11 10:32:51:Train Loss: 1.2087, cls: 0.0780, ce: 0.8053,crf: 0.2455, cam: 0.0799.
INFO:2022-04-11 10:32:51:Training: Epoch: 1/30
INFO:2022-04-11 10:32:51:Loss: 1.2087
INFO:2022-04-11 10:32:51:Validation: 1
INFO:2022-04-11 10:32:59:Testing Epoch: 1/30, mAP=0.9613, mIoU=0.6064, acc=0.7080
INFO:2022-04-11 10:32:59:Training: 2
INFO:2022-04-11 10:34:55:lr = [0.0007746677540007383, 0.007746677540007383, 0.011620016310011074]
INFO:2022-04-11 10:34:55:Train Loss: 0.9832, cls: 0.0696, ce: 0.6656,crf: 0.1730, cam: 0.0749.
INFO:2022-04-11 10:34:55:Training: Epoch: 2/30
INFO:2022-04-11 10:34:55:Loss: 0.9832
INFO:2022-04-11 10:34:55:Validation: 2
INFO:2022-04-11 10:35:03:Testing Epoch: 2/30, mAP=0.9646, mIoU=0.6515, acc=0.7080
INFO:2022-04-11 10:35:03:Training: 3
INFO:2022-04-11 10:36:59:lr = [0.0006978448920310331, 0.006978448920310332, 0.010467673380465498]
INFO:2022-04-11 10:36:59:Train Loss: 0.9102, cls: 0.0629, ce: 0.6165,crf: 0.1619, cam: 0.0690.
INFO:2022-04-11 10:36:59:Training: Epoch: 3/30
INFO:2022-04-11 10:36:59:Loss: 0.9102
INFO:2022-04-11 10:36:59:Validation: 3
INFO:2022-04-11 10:37:07:Testing Epoch: 3/30, mAP=0.9650, mIoU=0.6419, acc=0.7521
INFO:2022-04-11 10:37:07:Training: 4
INFO:2022-04-11 10:39:04:lr = [0.0006200683916118909, 0.006200683916118909, 0.009301025874178363]
INFO:2022-04-11 10:39:04:Train Loss: 0.8482, cls: 0.0585, ce: 0.5717,crf: 0.1520, cam: 0.0659.
INFO:2022-04-11 10:39:04:Training: Epoch: 4/30
INFO:2022-04-11 10:39:04:Loss: 0.8482
INFO:2022-04-11 10:39:04:Validation: 4
INFO:2022-04-11 10:39:12:Testing Epoch: 4/30, mAP=0.9626, mIoU=0.6507, acc=0.7273
INFO:2022-04-11 10:39:12:Training: 5
INFO:2022-04-11 10:41:12:lr = [0.0005411891037058208, 0.0054118910370582075, 0.008117836555587312]
INFO:2022-04-11 10:41:12:Train Loss: 0.7868, cls: 0.0576, ce: 0.5330,crf: 0.1299, cam: 0.0662.
INFO:2022-04-11 10:41:12:Training: Epoch: 5/30
INFO:2022-04-11 10:41:12:Loss: 0.7868
INFO:2022-04-11 10:41:12:Validation: 5
INFO:2022-04-11 10:41:20:Testing Epoch: 5/30, mAP=0.9683, mIoU=0.6747, acc=0.7218
INFO:2022-04-11 10:41:21:Training: 6
INFO:2022-04-11 10:43:22:lr = [0.00046100573766162786, 0.004610057376616279, 0.006915086064924417]
INFO:2022-04-11 10:43:22:Train Loss: 0.7359, cls: 0.0560, ce: 0.4887,crf: 0.1286, cam: 0.0626.
INFO:2022-04-11 10:43:22:Training: Epoch: 6/30
INFO:2022-04-11 10:43:22:Loss: 0.7359
INFO:2022-04-11 10:43:22:Validation: 6
INFO:2022-04-11 10:43:30:Testing Epoch: 6/30, mAP=0.9662, mIoU=0.6890, acc=0.7521
INFO:2022-04-11 10:43:30:Training: 7
INFO:2022-04-11 10:45:27:lr = [0.0003792323738936543, 0.003792323738936543, 0.0056884856084048144]
INFO:2022-04-11 10:45:27:Train Loss: 0.7292, cls: 0.0541, ce: 0.4882,crf: 0.1231, cam: 0.0638.
INFO:2022-04-11 10:45:27:Training: Epoch: 7/30
INFO:2022-04-11 10:45:27:Loss: 0.7292
INFO:2022-04-11 10:45:27:Validation: 7
INFO:2022-04-11 10:45:35:Testing Epoch: 7/30, mAP=0.9680, mIoU=0.6797, acc=0.7493
INFO:2022-04-11 10:45:35:Training: 8
INFO:2022-04-11 10:47:36:lr = [0.0002954321366096037, 0.0029543213660960365, 0.004431482049144056]
INFO:2022-04-11 10:47:36:Train Loss: 0.7095, cls: 0.0542, ce: 0.4748,crf: 0.1189, cam: 0.0615.
INFO:2022-04-11 10:47:36:Training: Epoch: 8/30
INFO:2022-04-11 10:47:36:Loss: 0.7095
INFO:2022-04-11 10:47:36:Validation: 8
INFO:2022-04-11 10:47:44:Testing Epoch: 8/30, mAP=0.9670, mIoU=0.6725, acc=0.7328
INFO:2022-04-11 10:47:45:Training: 9
INFO:2022-04-11 10:49:45:lr = [0.00020885717946126755, 0.002088571794612675, 0.003132857691919013]
INFO:2022-04-11 10:49:45:Train Loss: 0.6820, cls: 0.0509, ce: 0.4570,crf: 0.1150, cam: 0.0591.
INFO:2022-04-11 10:49:45:Training: Epoch: 9/30
INFO:2022-04-11 10:49:45:Loss: 0.6820
INFO:2022-04-11 10:49:45:Validation: 9
INFO:2022-04-11 10:49:53:Testing Epoch: 9/30, mAP=0.9661, mIoU=0.6809, acc=0.7410
INFO:2022-04-11 10:49:54:Training: 10
INFO:2022-04-11 10:51:51:lr = [0.00011793281191331187, 0.0011793281191331186, 0.0017689921786996781]
INFO:2022-04-11 10:51:51:Train Loss: 0.6709, cls: 0.0501, ce: 0.4471,crf: 0.1139, cam: 0.0599.
INFO:2022-04-11 10:51:51:Training: Epoch: 10/30
INFO:2022-04-11 10:51:51:Loss: 0.6709
INFO:2022-04-11 10:51:51:Validation: 10
INFO:2022-04-11 10:51:59:Testing Epoch: 10/30, mAP=0.9693, mIoU=0.6821, acc=0.7466
INFO:2022-04-11 10:51:59:Training: 11
INFO:2022-04-11 10:53:55:lr = [1.6560382712451324e-05, 0.00016560382712451323, 0.00024840574068676983]
INFO:2022-04-11 10:53:55:Train Loss: 0.6391, cls: 0.0504, ce: 0.4179,crf: 0.1133, cam: 0.0576.
INFO:2022-04-11 10:53:55:Training: Epoch: 11/30
INFO:2022-04-11 10:53:55:Loss: 0.6391
INFO:2022-04-11 10:53:55:Validation: 11
INFO:2022-04-11 10:54:03:Testing Epoch: 11/30, mAP=0.9678, mIoU=0.6854, acc=0.7576
INFO:2022-04-11 10:54:03:Training: 12
INFO:2022-04-11 10:56:02:lr = [9.559586023932047e-05, 0.0009559586023932047, 0.001433937903589807]
INFO:2022-04-11 10:56:02:Train Loss: 0.6462, cls: 0.0492, ce: 0.4261,crf: 0.1131, cam: 0.0578.
INFO:2022-04-11 10:56:02:Training: Epoch: 12/30
INFO:2022-04-11 10:56:02:Loss: 0.6462
INFO:2022-04-11 10:56:02:Validation: 12
INFO:2022-04-11 10:56:11:Testing Epoch: 12/30, mAP=0.9685, mIoU=0.6827, acc=0.7493
INFO:2022-04-11 10:56:11:Training: 13
INFO:2022-04-11 10:58:08:lr = [9.05215010050999e-05, 0.0009052150100509989, 0.0013578225150764984]
INFO:2022-04-11 10:58:08:Train Loss: 0.6488, cls: 0.0494, ce: 0.4258,crf: 0.1136, cam: 0.0600.
INFO:2022-04-11 10:58:08:Training: Epoch: 13/30
INFO:2022-04-11 10:58:08:Loss: 0.6488
INFO:2022-04-11 10:58:08:Validation: 13
INFO:2022-04-11 10:58:16:Testing Epoch: 13/30, mAP=0.9696, mIoU=0.6761, acc=0.7438
INFO:2022-04-11 10:58:16:Training: 14
INFO:2022-04-11 11:00:13:lr = [8.54153179675496e-05, 0.0008541531796754959, 0.0012812297695132438]
INFO:2022-04-11 11:00:13:Train Loss: 0.6213, cls: 0.0482, ce: 0.4065,crf: 0.1117, cam: 0.0549.
INFO:2022-04-11 11:00:13:Training: Epoch: 14/30
INFO:2022-04-11 11:00:13:Loss: 0.6213
INFO:2022-04-11 11:00:13:Validation: 14
INFO:2022-04-11 11:00:20:Testing Epoch: 14/30, mAP=0.9683, mIoU=0.6809, acc=0.7658
INFO:2022-04-11 11:00:21:Training: 15
INFO:2022-04-11 11:02:17:lr = [8.027496715621114e-05, 0.0008027496715621113, 0.001204124507343167]
INFO:2022-04-11 11:02:17:Train Loss: 0.6509, cls: 0.0508, ce: 0.4321,crf: 0.1093, cam: 0.0586.
INFO:2022-04-11 11:02:17:Training: Epoch: 15/30
INFO:2022-04-11 11:02:17:Loss: 0.6509
INFO:2022-04-11 11:02:17:Validation: 15
INFO:2022-04-11 11:02:25:Testing Epoch: 15/30, mAP=0.9701, mIoU=0.6767, acc=0.7410
INFO:2022-04-11 11:02:25:Training: 16
INFO:2022-04-11 11:04:21:lr = [7.509775106572544e-05, 0.0007509775106572544, 0.0011264662659858816]
INFO:2022-04-11 11:04:21:Train Loss: 0.6167, cls: 0.0479, ce: 0.4037,crf: 0.1085, cam: 0.0566.
INFO:2022-04-11 11:04:21:Training: Epoch: 16/30
INFO:2022-04-11 11:04:21:Loss: 0.6167
INFO:2022-04-11 11:04:21:Validation: 16
INFO:2022-04-11 11:04:29:Testing Epoch: 16/30, mAP=0.9686, mIoU=0.6781, acc=0.7548
INFO:2022-04-11 11:04:29:Training: 17
INFO:2022-04-11 11:06:25:lr = [6.988053376996817e-05, 0.0006988053376996817, 0.0010482080065495226]
INFO:2022-04-11 11:06:25:Train Loss: 0.6404, cls: 0.0486, ce: 0.4221,crf: 0.1113, cam: 0.0584.
INFO:2022-04-11 11:06:25:Training: Epoch: 17/30
INFO:2022-04-11 11:06:25:Loss: 0.6404
INFO:2022-04-11 11:06:25:Validation: 17
INFO:2022-04-11 11:06:34:Testing Epoch: 17/30, mAP=0.9675, mIoU=0.6748, acc=0.7355
INFO:2022-04-11 11:06:34:Training: 18
INFO:2022-04-11 11:08:31:lr = [6.461962678415633e-05, 0.0006461962678415633, 0.0009692944017623448]
INFO:2022-04-11 11:08:31:Train Loss: 0.6294, cls: 0.0486, ce: 0.4145,crf: 0.1068, cam: 0.0596.
INFO:2022-04-11 11:08:31:Training: Epoch: 18/30
INFO:2022-04-11 11:08:31:Loss: 0.6294
INFO:2022-04-11 11:08:31:Validation: 18
INFO:2022-04-11 11:08:38:Testing Epoch: 18/30, mAP=0.9686, mIoU=0.6746, acc=0.7493
INFO:2022-04-11 11:08:38:Training: 19
INFO:2022-04-11 11:10:35:lr = [5.931063196713951e-05, 0.0005931063196713951, 0.0008896594795070926]
INFO:2022-04-11 11:10:35:Train Loss: 0.6114, cls: 0.0465, ce: 0.3987,crf: 0.1109, cam: 0.0552.
INFO:2022-04-11 11:10:35:Training: Epoch: 19/30
INFO:2022-04-11 11:10:35:Loss: 0.6114
INFO:2022-04-11 11:10:35:Validation: 19
INFO:2022-04-11 11:10:43:Testing Epoch: 19/30, mAP=0.9680, mIoU=0.6753, acc=0.7548
INFO:2022-04-11 11:10:44:Training: 20
INFO:2022-04-11 11:12:40:lr = [5.394821928196066e-05, 0.0005394821928196065, 0.0008092232892294098]
INFO:2022-04-11 11:12:40:Train Loss: 0.6223, cls: 0.0478, ce: 0.4107,crf: 0.1068, cam: 0.0570.
INFO:2022-04-11 11:12:40:Training: Epoch: 20/30
INFO:2022-04-11 11:12:40:Loss: 0.6223
INFO:2022-04-11 11:12:40:Validation: 20
INFO:2022-04-11 11:12:48:Testing Epoch: 20/30, mAP=0.9690, mIoU=0.6736, acc=0.7631
INFO:2022-04-11 11:12:48:Training: 21
INFO:2022-04-11 11:14:44:lr = [4.8525801960019504e-05, 0.0004852580196001951, 0.0007278870294002926]
INFO:2022-04-11 11:14:44:Train Loss: 0.6042, cls: 0.0468, ce: 0.3945,crf: 0.1073, cam: 0.0556.
INFO:2022-04-11 11:14:44:Training: Epoch: 21/30
INFO:2022-04-11 11:14:44:Loss: 0.6042
INFO:2022-04-11 11:14:44:Validation: 21
INFO:2022-04-11 11:14:53:Testing Epoch: 21/30, mAP=0.9687, mIoU=0.6704, acc=0.7631
INFO:2022-04-11 11:14:53:Training: 22
INFO:2022-04-11 11:16:51:lr = [4.3035042509790234e-05, 0.0004303504250979023, 0.0006455256376468535]
INFO:2022-04-11 11:16:51:Train Loss: 0.6306, cls: 0.0480, ce: 0.4159,crf: 0.1086, cam: 0.0582.
INFO:2022-04-11 11:16:51:Training: Epoch: 22/30
INFO:2022-04-11 11:16:51:Loss: 0.6306
INFO:2022-04-11 11:16:51:Validation: 22
INFO:2022-04-11 11:16:59:Testing Epoch: 22/30, mAP=0.9690, mIoU=0.6723, acc=0.7466
INFO:2022-04-11 11:16:59:Training: 23
INFO:2022-04-11 11:18:56:lr = [3.746506364066295e-05, 0.0003746506364066295, 0.0005619759546099442]
INFO:2022-04-11 11:18:56:Train Loss: 0.6379, cls: 0.0474, ce: 0.4185,crf: 0.1115, cam: 0.0605.
INFO:2022-04-11 11:18:56:Training: Epoch: 23/30
INFO:2022-04-11 11:18:56:Loss: 0.6379
INFO:2022-04-11 11:18:56:Validation: 23
INFO:2022-04-11 11:19:04:Testing Epoch: 23/30, mAP=0.9703, mIoU=0.6698, acc=0.7438
INFO:2022-04-11 11:19:04:Training: 24
INFO:2022-04-11 11:21:01:lr = [3.180110627669995e-05, 0.0003180110627669995, 0.00047701659415049923]
INFO:2022-04-11 11:21:01:Train Loss: 0.6152, cls: 0.0475, ce: 0.4030,crf: 0.1075, cam: 0.0572.
INFO:2022-04-11 11:21:01:Training: Epoch: 24/30
INFO:2022-04-11 11:21:01:Loss: 0.6152
INFO:2022-04-11 11:21:01:Validation: 24
INFO:2022-04-11 11:21:09:Testing Epoch: 24/30, mAP=0.9692, mIoU=0.6700, acc=0.7493
INFO:2022-04-11 11:21:09:Training: 25
INFO:2022-04-11 11:23:06:lr = [2.6022049529615333e-05, 0.00026022049529615335, 0.00039033074294423]
INFO:2022-04-11 11:23:06:Train Loss: 0.6203, cls: 0.0478, ce: 0.4064,crf: 0.1095, cam: 0.0567.
INFO:2022-04-11 11:23:06:Training: Epoch: 25/30
INFO:2022-04-11 11:23:06:Loss: 0.6203
INFO:2022-04-11 11:23:06:Validation: 25
INFO:2022-04-11 11:23:15:Testing Epoch: 25/30, mAP=0.9681, mIoU=0.6670, acc=0.7493
INFO:2022-04-11 11:23:15:Training: 26
INFO:2022-04-11 11:25:13:lr = [2.0095262999833883e-05, 0.00020095262999833883, 0.00030142894499750827]
INFO:2022-04-11 11:25:13:Train Loss: 0.6228, cls: 0.0481, ce: 0.4065,crf: 0.1115, cam: 0.0568.
INFO:2022-04-11 11:25:13:Training: Epoch: 26/30
INFO:2022-04-11 11:25:13:Loss: 0.6228
INFO:2022-04-11 11:25:13:Validation: 26
INFO:2022-04-11 11:25:21:Testing Epoch: 26/30, mAP=0.9690, mIoU=0.6711, acc=0.7548
INFO:2022-04-11 11:25:21:Training: 27
INFO:2022-04-11 11:27:19:lr = [1.3963856593028266e-05, 0.00013963856593028265, 0.00020945784889542398]
INFO:2022-04-11 11:27:19:Train Loss: 0.6249, cls: 0.0479, ce: 0.4119,crf: 0.1075, cam: 0.0576.
INFO:2022-04-11 11:27:19:Training: Epoch: 27/30
INFO:2022-04-11 11:27:19:Loss: 0.6249
INFO:2022-04-11 11:27:19:Validation: 27
INFO:2022-04-11 11:27:27:Testing Epoch: 27/30, mAP=0.9689, mIoU=0.6696, acc=0.7548
INFO:2022-04-11 11:27:27:Training: 28
INFO:2022-04-11 11:29:25:lr = [7.50338904472446e-06, 7.50338904472446e-05, 0.0001125508356708669]
INFO:2022-04-11 11:29:25:Train Loss: 0.6081, cls: 0.0474, ce: 0.3983,crf: 0.1066, cam: 0.0558.
INFO:2022-04-11 11:29:25:Training: Epoch: 28/30
INFO:2022-04-11 11:29:25:Loss: 0.6081
INFO:2022-04-11 11:29:25:Validation: 28
INFO:2022-04-11 11:29:33:Testing Epoch: 28/30, mAP=0.9701, mIoU=0.6693, acc=0.7493
INFO:2022-04-11 11:29:33:Training: 29
INFO:2022-04-11 11:31:30:lr = [7.536334834191402e-08, 7.536334834191402e-07, 1.1304502251287102e-06]
INFO:2022-04-11 11:31:30:Train Loss: 0.6068, cls: 0.0478, ce: 0.3955,crf: 0.1056, cam: 0.0579.
INFO:2022-04-11 11:31:30:Training: Epoch: 29/30
INFO:2022-04-11 11:31:30:Loss: 0.6068
INFO:2022-04-11 11:31:30:Validation: 29
INFO:2022-04-11 11:31:39:Testing Epoch: 29/30, mAP=0.9689, mIoU=0.6703, acc=0.7466
